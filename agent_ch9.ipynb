{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN/RTk1P/bQkH/gXeCfM7yq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philosophynote/machine_learning/blob/main/agent_ch9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLPwF597QtDd",
        "outputId": "b047c684-c89c-484f-9735-20919ca5993d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.0\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai==0.2.0\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph==0.2.22\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.31)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.5)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.0) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.0)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph==0.2.22)\n",
            "  Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph==0.2.22) (1.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, tiktoken, langsmith, langgraph-checkpoint, langchain-openai, langgraph, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.0\n",
            "    Uninstalling langsmith-0.3.0:\n",
            "      Successfully uninstalled langsmith-0.3.0\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.15\n",
            "    Uninstalling langchain-0.3.15:\n",
            "      Successfully uninstalled langchain-0.3.15\n",
            "Successfully installed langchain-0.3.0 langchain-openai-0.2.0 langgraph-0.2.22 langgraph-checkpoint-1.0.12 langsmith-0.1.147 tenacity-8.5.0 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xd67C4n4QYyz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROLES = {\n",
        "    \"1\": {\n",
        "        \"name\": \"一般知識エキスパート\",\n",
        "        \"description\": \"幅広い分野の一般的な質問に答える\",\n",
        "        \"details\": \"幅広い分野の一般的な質問に対して、正確で分かりやすい回答を提供してください。\"\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"name\": \"生成AI製品エキスパート\",\n",
        "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
        "        \"details\": \"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください。\"\n",
        "    },\n",
        "    \"3\": {\n",
        "        \"name\": \"カウンセラー\",\n",
        "        \"description\": \"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
        "        \"details\": \"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "MnC_Y7FpQu1g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "\n",
        "from typing import Annotated\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field"
      ],
      "metadata": {
        "id": "Mkm3C-pvQwAQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(BaseModel):\n",
        "    query: str = Field(..., description=\"ユーザーからの質問\")\n",
        "    current_role: str = Field(\n",
        "        default=\"\", description=\"選定された回答ロール\"\n",
        "    )\n",
        "    messages: Annotated[list[str], operator.add] = Field(\n",
        "        default=[], description=\"回答履歴\"\n",
        "    )\n",
        "    current_judge: bool = Field(\n",
        "        default=False, description=\"品質チェックの結果\"\n",
        "    )\n",
        "    judgement_reason: str = Field(\n",
        "        default=\"\", description=\"品質チェックの判定理由\"\n",
        "    )"
      ],
      "metadata": {
        "id": "MaZFdovYRPKr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField"
      ],
      "metadata": {
        "id": "kcMVV1i1RVx-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
      ],
      "metadata": {
        "id": "oT9iYQPdRd_C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "-qlm8WGoRw5v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def selection_node(state: State) -> dict[str, Any]:\n",
        "    query = state.query\n",
        "    role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
        "\n",
        "選択肢:\n",
        "{role_options}\n",
        "\n",
        "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
        "\n",
        "質問: {query}\n",
        "\"\"\".strip()\n",
        "    )\n",
        "    # 選択肢の番号のみを返すことを期待したいため、max_tokensの値を1に変更\n",
        "    chain = prompt | llm.with_config(configurable=dict(max_tokens=1)) | StrOutputParser()\n",
        "    role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
        "\n",
        "    selected_role = ROLES[role_number.strip()][\"name\"]\n",
        "    return {\"current_role\": selected_role}\n",
        "\n"
      ],
      "metadata": {
        "id": "5gjWe34HR25F"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_node(state: State) -> dict[str, Any]:\n",
        "  query = state.query\n",
        "  role = state.current_role\n",
        "  role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
        "\n",
        "役割の詳細:\n",
        "{role_details}\n",
        "\n",
        "質問: {query}\n",
        "\n",
        "回答:\"\"\".strip()\n",
        "    )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
        "  return {\"messages\":  [answer]}"
      ],
      "metadata": {
        "id": "TtKTrIOgTb8Z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Judgement(BaseModel):\n",
        "    judge: bool = Field(default=False, description=\"判定結果\")\n",
        "    reason: str = Field(default=\"\", description=\"判定理由\")\n",
        "\n",
        "def check_node(state: State) -> dict[str, Any]:\n",
        "    query = state.query\n",
        "    answer = state.messages[-1]\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。\n",
        "また、その判断理由も説明してください。\n",
        "\n",
        "ユーザーからの質問: {query}\n",
        "回答: {answer}\n",
        "\"\"\".strip()\n",
        "    )\n",
        "    chain = prompt | llm.with_structured_output(Judgement)\n",
        "    result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
        "\n",
        "    return {\n",
        "        \"current_judge\": result.judge,\n",
        "        \"judgement_reason\": result.reason\n",
        "    }"
      ],
      "metadata": {
        "id": "Hrfgxi1oUaMl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "workflow = StateGraph(State)"
      ],
      "metadata": {
        "id": "QuC_sEvTUlYQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"selection\", selection_node)\n",
        "workflow.add_node(\"answering\", answer_node)\n",
        "workflow.add_node(\"check\", check_node)"
      ],
      "metadata": {
        "id": "gWUMhNqlUnh6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_entry_point(\"selection\")"
      ],
      "metadata": {
        "id": "dmshbg7rU4Nb"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_edge(\"selection\", \"answering\")\n",
        "workflow.add_edge(\"answering\", \"check\")"
      ],
      "metadata": {
        "id": "aAQj5BI9U8OK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END"
      ],
      "metadata": {
        "id": "sTgy5zV8U-WY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_conditional_edges(\n",
        "    \"check\",\n",
        "    lambda state: state.current_judge,\n",
        "    {True: END, False: \"selection\"}\n",
        ")"
      ],
      "metadata": {
        "id": "v1CPkLs-VBFA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiled = workflow.compile()"
      ],
      "metadata": {
        "id": "oVBmqnDzVSDD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = State(query=\"子供を産むことは人類にとって幸せなのでしょうか？\")\n",
        "result = compiled.invoke(initial_state)"
      ],
      "metadata": {
        "id": "LoRjO4NBVVM8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwLnFE88WYTk",
        "outputId": "8a9b102e-cfc2-44e0-a2dd-44cc87976bfd"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '子供を産むことは人類にとって幸せなのでしょうか？',\n",
              " 'current_role': 'カウンセラー',\n",
              " 'messages': ['この質問は非常に個人的で、答えは人それぞれ異なるかもしれません。子供を持つことが幸せかどうかは、個人の価値観、ライフスタイル、人生の目標によって大きく変わります。\\n\\n多くの人にとって、子供を持つことは大きな喜びや充実感をもたらします。子供の成長を見守り、家族としての絆を深めることは、人生において非常に意義深い経験となることが多いです。また、子供を育てることで得られる学びや成長も、親にとって大きな財産となるでしょう。\\n\\n一方で、子供を持つことには多くの責任や挑戦が伴います。育児には時間、エネルギー、経済的な負担がかかるため、これらを考慮に入れた上での決断が必要です。子供を持たない選択をする人も増えており、それもまた一つの幸せの形です。\\n\\n最終的には、自分自身の価値観や人生の目標に基づいて、どのような選択が自分にとって最も幸せなのかを考えることが大切です。もしこのテーマについてさらに深く考えたい場合や、具体的な悩みがある場合は、信頼できる人や専門家に相談することも一つの方法です。あなたの選択が、あなた自身にとって最も満足のいくものであることを願っています。'],\n",
              " 'current_judge': True,\n",
              " 'judgement_reason': '回答は非常にバランスが取れており、個人の価値観や状況に応じた多様な視点を提供しています。子供を持つことの利点と挑戦の両方を公平に説明し、最終的な決断は個人の価値観に基づくべきであると強調しています。また、専門家への相談を勧めることで、より深い理解を促しています。全体として、質問に対する適切で包括的な回答です。'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7FiPrzfWnVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}